{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaL4","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, InputExample, losses, models\nfrom torch.utils.data import DataLoader\n\n# Step 1: Load BGE model\nmodel_name = \"BAAI/bge-small-en\"\nword_embedding_model = models.Transformer(model_name)\npooling_model = models.Pooling(\n    word_embedding_model.get_word_embedding_dimension(),\n    pooling_mode=\"mean\"\n)\nmodel = SentenceTransformer(modules=[word_embedding_model, pooling_model])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T21:26:59.574134Z","iopub.execute_input":"2025-05-07T21:26:59.574453Z"}},"outputs":[{"name":"stderr","text":"2025-05-07 21:27:17.268046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746653237.512925      73 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746653237.583421      73 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Step 2: Instruction prefix for BGE models (recommended by BAAI)\ninstruction = \"Represent this sentence for retrieval: \"\n\n# Step 3: Prepare training data (query, positive passage)\n# In real use, load this from your dataset\ntrain_examples = [\n    InputExample(texts=[instruction + \"what is artificial intelligence\", \"Artificial intelligence is the simulation of human intelligence.\"]),\n    InputExample(texts=[instruction + \"capital of France\", \"Paris is the capital of France.\"]),\n    InputExample(texts=[instruction + \"what is machine learning\", \"Machine learning is a subset of artificial intelligence focused on data-driven models.\"]),\n    InputExample(texts=[instruction + \"benefits of exercise\", \"Regular physical activity improves cardiovascular health and boosts mood.\"]),\n    InputExample(texts=[instruction + \"python programming language\", \"Python is a popular programming language known for its readability.\"]),\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_examples[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4: DataLoader\ntrain_dataloader = DataLoader(train_examples, shuffle=True, batch_size=4)\n\n# Step 5: Define the MultipleNegativesRankingLoss\ntrain_loss = losses.MultipleNegativesRankingLoss(model)\n\n# Step 6: Train the model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(\n    train_objectives=[(train_dataloader, train_loss)],\n    epochs=3,\n    warmup_steps=2,\n    evaluation_steps=2,\n    output_path=\"./bge-mnr-finetuned\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Validation data\nval_examples = [\n    InputExample(texts=[instruction + \"what is artificial intelligence\", \"AI simulates human intelligence.\"]),\n    InputExample(texts=[instruction + \"capital of Germany\", \"Berlin is the capital of Germany.\"]),\n    InputExample(texts=[instruction + \"benefits of sleep\", \"Sleep improves mental performance.\"]),\n    InputExample(texts=[instruction + \"define programming\", \"Programming is the act of writing code.\"]),\n]\nval_dataloader = DataLoader(val_examples, shuffle=False, batch_size=2)\nval_loss_fn = losses.MultipleNegativesRankingLoss(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 7: Use the model (example)\nmodel = SentenceTransformer(\"./bge-mnr-finetuned\")\nquery = instruction + \"capital of France\"\ndocs = [\"Paris is the capital of France.\", \"Berlin is in Germany.\", \"Apples are fruits.\"]\n\n# Compute embeddings and similarities\nquery_emb = model.encode(query, convert_to_tensor=True)\ndoc_embs = model.encode(docs, convert_to_tensor=True)\n\nimport torch\ncos_sim = torch.nn.functional.cosine_similarity(query_emb, doc_embs)\nfor doc, score in zip(docs, cos_sim):\n    print(f\"Doc: {doc} \\nScore: {score.item():.4f}\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}